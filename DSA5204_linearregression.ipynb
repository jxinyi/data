{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "In this notebook, we introduce basic linear models for regression and classification. We will use basic functionalities of the machine learning library `scikit-learn`. Install this by\n",
    "```\n",
    "$pip install scikit-learn\n",
    "```\n",
    "Documentation is found [here](https://scikit-learn.org/stable/).\n",
    "\n",
    "We will also need `pandas`, `numpy` and plotting libraries `matplotlib` and `seaborn`.\n",
    "```\n",
    "$pip install numpy pandas matplotlib seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/matplotlib/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting matplotlib\n",
      "  Downloading matplotlib-3.7.0-cp311-cp311-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m22.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:09\u001b[0mm\n",
      "\u001b[?25h  Downloading matplotlib-3.6.3-cp311-cp311-macosx_11_0_arm64.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m27.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25h  Downloading matplotlib-3.6.2-cp311-cp311-macosx_11_0_arm64.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/7.2 MB\u001b[0m \u001b[31m20.5 kB/s\u001b[0m eta \u001b[36m0:01:57\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 437, in _error_catcher\n",
      "    yield\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 526, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py\", line 465, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py\", line 1278, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py\", line 1134, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/cli/base_command.py\", line 160, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/cli/req_command.py\", line 247, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/commands/install.py\", line 400, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 373, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 211, in _attempt_to_pin_criterion\n",
      "    for candidate in criterion.candidates:\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "                ^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "                                       ^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 297, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 162, in __init__\n",
      "    self.dist = self._prepare()\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 231, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 308, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 491, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 536, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "                 ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 166, in unpack_url\n",
      "    file = get_http_url(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 107, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/network/download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 621, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 559, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/3.6.1/libexec/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 442, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook', font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "sns.set_style(\"darkgrid\")\n",
    "np.random.seed(123)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singapore Housing Dataset\n",
    "\n",
    "This dataset is obtained from a [Govtech database](https://data.gov.sg). Read the description in the website for more information. We are going to only use a subset of this data as a simple demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "The data has been downloaded into the repository for convenience. You also also get this (and more) [here](https://data.gov.sg/dataset/resale-flat-prices). We will only use the dataset `resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv` in this simple demo. Besure to place the data in a directory `data/` relative to the directory of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv('./data/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Some data should be numerical but we can't easily work with them, so let's do some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_years(years_and_months):\n",
    "    \"\"\"\n",
    "    Convert n years m months to (n + m/12) years\n",
    "    \n",
    "    \"\"\"\n",
    "    split = years_and_months.split(' ')\n",
    "    if len(split) == 2:\n",
    "        return float(split[0])\n",
    "    elif len(split) == 4:\n",
    "        return float(split[0]) + float(split[2]) / 12.0\n",
    "    else:\n",
    "        raise ValueError('Wrong format.')\n",
    "\n",
    "def average_storey(storey_range):\n",
    "    \"\"\"\n",
    "    Convert n TO m to (n+m)/2\n",
    "    \"\"\"\n",
    "    split = storey_range.split(' TO ')\n",
    "    if len(split) == 2:\n",
    "        return 0.5 * (float(split[0]) + float(split[1]))\n",
    "    else:\n",
    "        raise ValueError('Wrong format.')\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset['remaining_lease'] = dataset['remaining_lease'].apply(convert_to_years)\n",
    "dataset['storey'] = dataset['storey_range'].apply(average_storey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Visualizations\n",
    "\n",
    "We will visualize the data to find some patterns. The `seaborn` plotting library has some useful tools to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 8))\n",
    "\n",
    "sns.barplot(\n",
    "    x='resale_price',\n",
    "    y='town',\n",
    "    data=dataset,\n",
    "    orient='h',\n",
    "    ci=\"sd\",\n",
    "    ax=ax[0]\n",
    ")\n",
    "\n",
    "sns.barplot(\n",
    "    x='resale_price',\n",
    "    y='storey',\n",
    "    data=dataset,\n",
    "    orient='h',\n",
    "    ci=\"sd\",\n",
    "    ax=ax[1]\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x='resale_price',\n",
    "    y='floor_area_sqm',\n",
    "    hue='remaining_lease',\n",
    "    data=dataset,\n",
    "    ax=ax[2]\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xticklabels(a.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "We will know proceed to fit some models to predict the *resale_price* given some input descriptors. This is a classical regression problem. \n",
    "\n",
    "To evaluate our machine learning models, we should have at least 1 hold-out test set that is untouched by our learning algorithm, until evaluation time. Since no hyper-parameter tuning is performed, it is sufficient to keep a single test set for this purpose. We use some handy functions from `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = train_test_split(dataset, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "We can see from the visualization that floor area is related to price. Rather, we should know this without seeing any data. We now try to regress the resale price from floor area alone and see how we do. \n",
    "\n",
    "Instead of coding our own ordinary least squares solver, `sklearn` (and many other libraries) have ready-made implementations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 'floor_area_sqm'\n",
    "outputs = 'resale_price'\n",
    "\n",
    "x_train = dataset_train[inputs][:, np.newaxis]\n",
    "x_test = dataset_test[inputs][:, np.newaxis]\n",
    "\n",
    "y_train = dataset_train[outputs]\n",
    "y_test = dataset_test[outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    ")\n",
    "y_hat_train = regressor.predict(x_train)\n",
    "y_hat_test = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Regression Result\n",
    "\n",
    "Since we are working in one dimension, it is possible to visualize our linear fit.\n",
    "\n",
    "Note that the following can be directly reproduced by a single `sns.regplot` call from `seaborn`, without explicitly using `LinearRegression()` from `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=x_train.ravel(),\n",
    "    y=y_train,\n",
    "    ax=ax[0],\n",
    "    alpha=0.5,\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=x_train.ravel(),\n",
    "    y=y_hat_train,\n",
    "    ax=ax[0],\n",
    "    color='red',\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=x_test.ravel(),\n",
    "    y=y_test,\n",
    "    ax=ax[1],\n",
    "    alpha=0.5,\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=x_test.ravel(),\n",
    "    y=y_hat_test,\n",
    "    ax=ax[1],\n",
    "    color='red',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel(inputs)\n",
    "    a.set_ylabel(outputs)\n",
    "\n",
    "    \n",
    "ax[0].set_title('Train set')\n",
    "ax[1].set_title('Test set')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can directly compare our predicted resale prices with the ground truth. This works if we have higher dimensional inputs so that a linear fit is difficult to plot graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=y_train,\n",
    "    y=y_hat_train,\n",
    "    ax=ax[0],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=y_test,\n",
    "    y=y_hat_test,\n",
    "    ax=ax[1],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel('{} (true)'.format(outputs))\n",
    "    a.set_ylabel('{} (predict)'.format(outputs))\n",
    "    a.set_xlim(1.5*10**5, 10**6)\n",
    "    a.set_ylim(1.5*10**5, 10**6)\n",
    "    a.plot(a.get_xlim(), a.get_ylim(), ls='--', c='k')\n",
    "\n",
    "\n",
    "    \n",
    "ax[0].set_title('Train set')\n",
    "ax[1].set_title('Test set')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying the Error\n",
    "\n",
    "Just looking at the fit doesn't tell us very precise information. Therefore, it is often better to quantify the error. One simple metric is the mean-square difference between the predicted outputs and the actual outputs. But this is not the only one! You are encouraged to look at [`sklearn.metrics`](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) to find more ways to evaluate the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse_scaled(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    scale = np.sqrt(np.mean(y_true**2))\n",
    "    return rmse/scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Scaled RMSE: \\n {} (Train) \\n {} (Test)'.format(\n",
    "        rmse_scaled(y_train, y_hat_train),\n",
    "        rmse_scaled(y_test, y_hat_test),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "\n",
    "Simple linear regression gave about 26% error. Can we do better by going to larger hypothesis spaces? Let us now try a **polynomial regression** up to degree 3. This is an example of a linear basis model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = PolynomialFeatures(degree=3)\n",
    "x_poly_train = phi.fit_transform(x_train)\n",
    "x_poly_test = phi.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_poly = LinearRegression()\n",
    "regressor_poly.fit(\n",
    "    X=x_poly_train,\n",
    "    y=y_train,\n",
    ")\n",
    "y_hat_poly_train = regressor_poly.predict(x_poly_train)\n",
    "y_hat_poly_test = regressor_poly.predict(x_poly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=x_train.ravel(),\n",
    "    y=y_train,\n",
    "    ax=ax[0],\n",
    "    alpha=0.5,\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=x_train.ravel(),\n",
    "    y=y_hat_poly_train,\n",
    "    ax=ax[0],\n",
    "    color='red',\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=x_test.ravel(),\n",
    "    y=y_test,\n",
    "    ax=ax[1],\n",
    "    alpha=0.5,\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=x_test.ravel(),\n",
    "    y=y_hat_poly_test,\n",
    "    ax=ax[1],\n",
    "    color='red',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel(inputs)\n",
    "    a.set_ylabel(outputs)\n",
    "\n",
    "    \n",
    "ax[0].set_title('Train set')\n",
    "ax[1].set_title('Test set')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=y_train,\n",
    "    y=y_hat_poly_train,\n",
    "    ax=ax[0],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=y_test,\n",
    "    y=y_hat_poly_test,\n",
    "    ax=ax[1],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel('{} (true)'.format(outputs))\n",
    "    a.set_ylabel('{} (predict)'.format(outputs))\n",
    "    a.set_xlim(1.5*10**5, 10**6)\n",
    "    a.set_ylim(1.5*10**5, 10**6)\n",
    "    a.plot(a.get_xlim(), a.get_ylim(), ls='--', c='k')\n",
    "\n",
    "\n",
    "    \n",
    "ax[0].set_title('Train set')\n",
    "ax[1].set_title('Test set')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Scaled RMSE: \\n {} (Train) \\n {} (Test)'.format(\n",
    "        rmse_scaled(y_train, y_hat_poly_train),\n",
    "        rmse_scaled(y_test, y_hat_poly_test),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like polynomial regression didn't really improve on the simple linear regression result. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including More Design Variables in Linear Regression\n",
    "\n",
    "Clearly, the size of the house is not the only factor determining price. Let us now include some other factors which may contribute. In this case, the regression problem is defined in higher dimenions.\n",
    "\n",
    "Note that from the viewpoint of approximation, we are also using a bigger **hypothesis space**, but not in the same way as a polynomial basis in one dimension. In the first linear regression example, we are using the hypothesis space consisting of all functions which are affine in *floor_area_sqm* and constant in the other dependent variables. Now, we are using the hypothesis space consisting of affine functions of more than one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['town', 'floor_area_sqm', 'remaining_lease', 'storey']\n",
    "outputs = 'resale_price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset_train[dataset_train.columns.intersection(inputs)]\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the \"town\" column are nominal/categorical variables, so let us perform a **one-hot encoding**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.get_dummies(x_train)\n",
    "y_train = dataset_train[outputs]\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we repeat this for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = dataset_test[dataset_test.columns.intersection(inputs)]\n",
    "x_test = pd.get_dummies(x_test)\n",
    "y_test = dataset_test[outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we train the regressor in these new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    ")\n",
    "y_hat_train = regressor.predict(x_train)\n",
    "y_hat_test = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=y_train,\n",
    "    y=y_hat_train,\n",
    "    ax=ax[0],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=y_test,\n",
    "    y=y_hat_test,\n",
    "    ax=ax[1],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel('{} (true)'.format(outputs))\n",
    "    a.set_ylabel('{} (predict)'.format(outputs))\n",
    "    a.set_xlim(1.5*10**5, 10**6)\n",
    "    a.set_ylim(1.5*10**5, 10**6)\n",
    "    a.plot(a.get_xlim(), a.get_ylim(), ls='--', c='k')\n",
    "\n",
    "\n",
    "    \n",
    "ax[0].set_title('Train set')\n",
    "ax[1].set_title('Test set')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Scaled RMSE: \\n {} (Train) \\n {} (Test)'.format(\n",
    "        rmse_scaled(y_train, y_hat_train),\n",
    "        rmse_scaled(y_test, y_hat_test),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe from the fit and the RMSE that we are doing quite a bit better than the univariate linear case. Can you improve on this:\n",
    "  *  Better accuracy?\n",
    "  *  Smaller number of features?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
